{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learnig the representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RepresentationModels' from '/home/paul/Documents/3AI/SolarEnergyMaterials/RepresentationModels.py'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependecies\n",
    "import importlib\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import RepresentationModels as RM\n",
    "importlib.reload(RepresentationModels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pasted models\n",
    "here for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Representation learning:\n",
    "    Goal: use unsupervised learning techniques to learn a representation of given data.\n",
    "    The hope is that this representation will be useful to reduce the amount of data that is needed for training the supervised model for solving the actual task.\n",
    "    To verify how good the learned representation is, train a supervised model using these representations that predicts the available pretrain labels.\n",
    "\n",
    "    Methology:\n",
    "    1. Create a several neural networks that learn to encode the data into a representation.\n",
    "    2. Train a supervised model on each of the learned representations. The superverised model trained on the different representations should be very shallow (1 or two fully connected layers) and should be trained for a very short time. The goal is to make the performance of the encoders comparable.\n",
    "'''\n",
    "\n",
    "# Dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "'''\n",
    "    Autoencoder for dimensionality reduction:\n",
    "    Both encoder and decoder using three linear layers\n",
    "'''\n",
    "\n",
    "# for this to make sense the encoding dimension should be significantly smaller than the input dimension\n",
    "# specifically, the encoding_dim*3 shold be smaller than the input_size\n",
    "class LinearAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, encoding_dim):\n",
    "        super(LinearAutoencoder, self).__init__()\n",
    "        # encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, encoding_dim*3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(encoding_dim*3), int(encoding_dim*2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoding_dim*2, encoding_dim)\n",
    "        )\n",
    "        # decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, encoding_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoding_dim*2, encoding_dim*3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoding_dim*3, input_size),\n",
    "            nn.Sigmoid() # the feature values are between 0 and 1\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "'''\n",
    "    Autocoder for dimensionality reduction:\n",
    "    Using three convolutional/deconvolutional layers for encoder/decoder\n",
    "'''\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self, number_filters):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        # encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, number_filters*3, kernel_size=3, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(number_filters*3, number_filters*2, kernel_size=3, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(number_filters*2, number_filters, kernel_size=3, stride=2, padding=0)\n",
    "        )\n",
    "        # decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(number_filters, number_filters*2, kernel_size=3, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(number_filters*2, number_filters*3, kernel_size=3, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(number_filters*3, 1, kernel_size=3, stride=2, padding=0, output_padding=1), # need out padding to get the right size\n",
    "            nn.Sigmoid() # the feature values are between 0 and 1\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = x.squeeze(1)\n",
    "        return x\n",
    "    \n",
    "'''\n",
    "    Autocoder for dimensionality reduction:\n",
    "    Using two convolutional/deconvolutional layers and one fully connected layer for both encoder and decoder\n",
    "'''\n",
    "class ConvLinearAutoencoder(nn.Module):\n",
    "    def __init__(self, number_filters, encoding_dim):\n",
    "        super(ConvLinearAutoencoder, self).__init__()\n",
    "        self.number_filters = number_filters\n",
    "        # encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, number_filters*2, kernel_size=3, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(number_filters*2, number_filters, kernel_size=3, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "        ) \n",
    "        # bottleneck layer\n",
    "        self.fcencoder = nn.Linear(249*number_filters, encoding_dim)\n",
    "        self.fcdecoder = nn.Linear(encoding_dim, 249*number_filters)\n",
    "\n",
    "        # decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(number_filters, number_filters*2, kernel_size=3, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(number_filters*2, 1, kernel_size=3, stride=2, padding=0),\n",
    "            nn.Sigmoid() # the feature values are between 0 and 1\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 249*self.number_filters)\n",
    "        x = self.fcencoder(x)\n",
    "        x = self.fcdecoder(x)\n",
    "        x = x.view(-1,self.number_filters, 249)\n",
    "        x = self.decoder(x)\n",
    "        x = x.squeeze(1)\n",
    "        return x\n",
    "    \n",
    "# contractive loss function\n",
    "def contractive_loss(W, x, recons_x, h, lam=1e-4):\n",
    "    mse_loss = nn.MSELoss()(recons_x, x)\n",
    "    \n",
    "    dh = h * (1 - h) # Derivative of sigmoid\n",
    "    w_sum = torch.sum(Variable(W)**2, dim=1)\n",
    "    w_sum = w_sum.unsqueeze(1) # Shape to 2D tensor\n",
    "    contractive_loss = torch.sum(torch.mm(dh**2, w_sum), 0)\n",
    "    return mse_loss + contractive_loss.mul_(lam)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.unpack_archive(\"drive/MyDrive/SolarEnergyMaterials/task4.zip\", \"/content/data\")\n",
    "shutil.unpack_archive(\"data/task4_hr35z9/pretrain_features.csv.zip\", \"/content/data\")\n",
    "shutil.unpack_archive(\"data/task4_hr35z9/pretrain_labels.csv.zip\", \"/content/data\")\n",
    "shutil.unpack_archive(\"data/task4_hr35z9/train_features.csv.zip\", \"/content/data\")\n",
    "shutil.unpack_archive(\"data/task4_hr35z9/train_labels.csv.zip\", \"/content/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrain_data(batch_size = 64):\n",
    "    batch_size = 64\n",
    "\n",
    "    random.seed(17)\n",
    "    test_ind = set()\n",
    "\n",
    "    pre_train_size = 50000\n",
    "\n",
    "    while len(test_ind) < 10000: \n",
    "        test_ind.add(random.randint(0, pre_train_size-1))\n",
    "\n",
    "    features =[]\n",
    "    labels = []\n",
    "\n",
    "    with open(\"data/pretrain_features.csv\", 'r') as f:\n",
    "        for row in f:\n",
    "            features.append(row)\n",
    "\n",
    "    with open(\"data/pretrain_labels.csv\", 'r') as f:\n",
    "        for row in f:\n",
    "            labels.append(row)\n",
    "\n",
    "    # remove header\n",
    "    features = features[1:]\n",
    "    labels = labels[1:]\n",
    "\n",
    "    # first try to note use representation of the molecules, only the extracted features\n",
    "    features = [list(map(float,row.split(',')[2:])) for row in features]\n",
    "    labels = [float(row.split(',')[1]) for row in labels]\n",
    "\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    test_features = []\n",
    "    test_labels = []\n",
    "\n",
    "\n",
    "    for i in range(len(features)):\n",
    "        if i in test_ind:\n",
    "            test_features.append(features[i])\n",
    "            test_labels.append(labels[i])\n",
    "        else:\n",
    "            train_features.append(features[i])\n",
    "            train_labels.append(labels[i])\n",
    "\n",
    "    # does not seem to make sense to normalize the data since it is very sparse\n",
    "    # normalize train_features\n",
    "    # train_features = (train_features - np.mean(train_features, axis=0)) / (np.std(train_features, axis=0)+EPSILON)\n",
    "\n",
    "    # normalize test_features\n",
    "    # test_features = (test_features - np.mean(test_features, axis=0)) / (np.std(test_features, axis=0)+EPSILON)\n",
    "\n",
    "    # convert into tensor dataset\n",
    "    train_features = torch.tensor(train_features, dtype=torch.float)\n",
    "    train_labels = torch.tensor(train_labels, dtype=torch.float)\n",
    "    test_features = torch.tensor(test_features, dtype=torch.float)\n",
    "    test_labels = torch.tensor(test_labels, dtype=torch.float)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_features, test_labels) \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_pretrain_data(batch_size = 64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop:\n",
    "def train_linear_encoder(model, dataloader, epochs):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            X_pred = model(X)\n",
    "            loss = loss_fn(X_pred, X)\n",
    "            loss.backward()  \n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, batch+1, len(dataloader), loss.item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearEncoder = RM.LinearAutoencoder(1000, 128)\n",
    "train_linear_encoder(LinearEncoder, train_loader, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [1/625], Loss: 0.2654\n",
      "Epoch [1/10], Batch [101/625], Loss: 0.0485\n",
      "Epoch [1/10], Batch [201/625], Loss: 0.0480\n",
      "Epoch [1/10], Batch [301/625], Loss: 0.0474\n",
      "Epoch [1/10], Batch [401/625], Loss: 0.0482\n",
      "Epoch [1/10], Batch [501/625], Loss: 0.0465\n",
      "Epoch [1/10], Batch [601/625], Loss: 0.0477\n",
      "Epoch [2/10], Batch [1/625], Loss: 0.0485\n",
      "Epoch [2/10], Batch [101/625], Loss: 0.0474\n",
      "Epoch [2/10], Batch [201/625], Loss: 0.0476\n",
      "Epoch [2/10], Batch [301/625], Loss: 0.0484\n",
      "Epoch [2/10], Batch [401/625], Loss: 0.0469\n",
      "Epoch [2/10], Batch [501/625], Loss: 0.0492\n",
      "Epoch [2/10], Batch [601/625], Loss: 0.0480\n",
      "Epoch [3/10], Batch [1/625], Loss: 0.0474\n",
      "Epoch [3/10], Batch [101/625], Loss: 0.0483\n",
      "Epoch [3/10], Batch [201/625], Loss: 0.0407\n",
      "Epoch [3/10], Batch [301/625], Loss: 0.0203\n",
      "Epoch [3/10], Batch [401/625], Loss: 0.0225\n",
      "Epoch [3/10], Batch [501/625], Loss: 0.0220\n",
      "Epoch [3/10], Batch [601/625], Loss: 0.0221\n",
      "Epoch [4/10], Batch [1/625], Loss: 0.0230\n",
      "Epoch [4/10], Batch [101/625], Loss: 0.0217\n",
      "Epoch [4/10], Batch [201/625], Loss: 0.0222\n",
      "Epoch [4/10], Batch [301/625], Loss: 0.0227\n",
      "Epoch [4/10], Batch [401/625], Loss: 0.0223\n",
      "Epoch [4/10], Batch [501/625], Loss: 0.0218\n",
      "Epoch [4/10], Batch [601/625], Loss: 0.0219\n",
      "Epoch [5/10], Batch [1/625], Loss: 0.0217\n",
      "Epoch [5/10], Batch [101/625], Loss: 0.0208\n",
      "Epoch [5/10], Batch [201/625], Loss: 0.0221\n",
      "Epoch [5/10], Batch [301/625], Loss: 0.0224\n",
      "Epoch [5/10], Batch [401/625], Loss: 0.0223\n",
      "Epoch [5/10], Batch [501/625], Loss: 0.0214\n",
      "Epoch [5/10], Batch [601/625], Loss: 0.0222\n",
      "Epoch [6/10], Batch [1/625], Loss: 0.0222\n",
      "Epoch [6/10], Batch [101/625], Loss: 0.0223\n",
      "Epoch [6/10], Batch [201/625], Loss: 0.0218\n",
      "Epoch [6/10], Batch [301/625], Loss: 0.0230\n",
      "Epoch [6/10], Batch [401/625], Loss: 0.0221\n",
      "Epoch [6/10], Batch [501/625], Loss: 0.0218\n",
      "Epoch [6/10], Batch [601/625], Loss: 0.0214\n",
      "Epoch [7/10], Batch [1/625], Loss: 0.0215\n",
      "Epoch [7/10], Batch [101/625], Loss: 0.0213\n",
      "Epoch [7/10], Batch [201/625], Loss: 0.0219\n",
      "Epoch [7/10], Batch [301/625], Loss: 0.0219\n",
      "Epoch [7/10], Batch [401/625], Loss: 0.0222\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m ConvEncoder \u001b[39m=\u001b[39m RM\u001b[39m.\u001b[39mConvAutoencoder(\u001b[39m32\u001b[39m)\n\u001b[1;32m      2\u001b[0m test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_loader))\n\u001b[0;32m----> 3\u001b[0m train_linear_encoder(ConvEncoder, train_loader, \u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[40], line 11\u001b[0m, in \u001b[0;36mtrain_linear_encoder\u001b[0;34m(model, dataloader, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m X_pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     10\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(X_pred, X)\n\u001b[0;32m---> 11\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()  \n\u001b[1;32m     12\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     14\u001b[0m \u001b[39mif\u001b[39;00m batch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/3AI/SolarEnergyMaterials/env/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/3AI/SolarEnergyMaterials/env/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ConvEncoder = RM.ConvAutoencoder(32)\n",
    "test = next(iter(train_loader))\n",
    "train_linear_encoder(ConvEncoder, train_loader, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder with Linear Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 6, 249])\n",
      "torch.Size([64, 6, 249])\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(RepresentationModels)\n",
    "ConvLinearEncoder = RM.ConvLinearAutoencoder(6, 90)\n",
    "test = next(iter(train_loader))[0]\n",
    "p = ConvLinearEncoder(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
